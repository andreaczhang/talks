<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Electronic Health Record data</title>
    <meta charset="utf-8" />
    <meta name="author" content="Chi Zhang" />
    <link href="libs/remark-css/hygge.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Electronic Health Record data
## opportunities, challenges and feature learning
### Chi Zhang
### 2019-05-24, internal seminar @ OCBE

---

class: middle






# Outline

### EHR data and challenges 

### Feature learning and application in EHR 

### 2 methods for MIMIC III data
#### 1. LSTM autoencoder
#### 2. Tensor decomposition 



---

# Electronic Health Records

Initially used for billing and administrative purposes

Routinely generated patient data from: 
- bed side monitors, lab tests 

&lt;img src="./img/img2.png" width="90%" style="display: block; margin: auto;" /&gt;

- More specialised: images such as waveforms

- Administration: demographics

---
#### Clinical notes 

&lt;img src="./img/img1.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---
class: middle

# Who benefits from EHR research?
#### Patients 
- disease progression prediction / early detection
  - e.g. heart failure, &lt;span style = 'color:maroon'&gt;(Choi 2016)&lt;/span&gt;
  - in-hospital mortality, &lt;span style = 'color:maroon'&gt;(Suresh 2018)&lt;/span&gt;
  - Parkinson's disease stage &lt;span style = 'color:maroon'&gt;(Che 2017)&lt;/span&gt;



#### Medical professionals 
- automate diagnosis
  - image evaluation: detect hip fracture from X-ray &lt;span style = 'color:maroon'&gt;(Gale 2017)&lt;/span&gt;
- automate routine process
  - summarize content from medical records &lt;span style = 'color:maroon'&gt;(McCoy 2018)&lt;/span&gt; 
  
#### Institution: hospitals 
- cost reduction 
- privacy protection 
  






 
---

## Research topics

Number of Google Scholar publications relating to **deep EHR** until 2017 &lt;span style = 'color:maroon'&gt;(Shickel 2018 Survey)&lt;/span&gt;

&lt;img src="./img/imgTopics.png" width="70%" style="display: block; margin: auto;" /&gt;









---
# Challenge 1: Availability 

&lt;img src="./img/imgChallenge0.png" width="70%" style="display: block; margin: auto;" /&gt;

--
#### Privacy protection
- no data at all

- or: 'brutal' anonymisation






---
# Lifesaver: MIMIC III data

### ICU data 
Pros: relatively complete

  - demographics, vital sign measurements, lab test results, 
  - procedures, medications, imaging reports
  - notes 
  
Cons: severely ill, multiple diagnosis within one same subject

--
### MIMIC III - Medical Information Mart for Intensive Care
- Critical care units, Beth Israel Deaconess Medical Center (Boston, US), 2001-2012 
- over 50,000 records for 30,000+ patients 
- De-identification: randomised time stamp 




---
Static data (table **admissions**)
&lt;img src="./img/imgMimic1.png" width="90%" style="display: block; margin: auto;" /&gt;

--
Dynamic data (table ** chartevents **)
&lt;img src="./img/imgMimic2.png" width="70%" style="display: block; margin: auto;" /&gt;

--
Information scattering around: 26 such tables, possibly large (330 million rows in ** chartevents **)

---
### Connect PostgreSQL Database with R 


```r
library(RPostgreSQL)
drv &lt;- dbDriver("PostgreSQL")        # PostgreSQL driver
con &lt;- dbConnect(drv, 
                 dbname = "mimicbig",    # database name
                 host = "localhost", 
                 port = 5432,
                 user = "chizhang", 
                 password = pw)
query &lt;- 'SELECT * FROM admissions WHERE subject_id = 10006'
record &lt;- dbGetQuery(con, statement = query)
```

-- 
#### Comments:

Know what information you need;

Partition large tables for speed.

---
# Challenge 2: data quality

**Digital artifact corruption**

- Undesired alteration in data due to technical reasons
- e.g. accidental removal of sensor


**Inconsistency and duplications**
- Various database systems within one hospital
- Example 1: Carevue and Metavision within MIMIC III, 2 sets of item IDs
- Example 2: measurement recorded by different staff into different systems



**Missingness**
- at random?
- not at random? 



**lack of labels**
Makes predictive models hard

---
# Challenge 3: Multi-modality

Numeric measurements

Categorical information: diagnosis code, ethnicity

Free text

Time stamp 

Images and signals: ECG waveforms

Genomic information 


---
# Challenge 4: Irregularity (length)

Unequal length of measurements: from a few hours to a few thousand hours 


```r
los &lt;- read.csv('~/Documents/Data/los.csv')
loshours &lt;- los*24
summary(loshours$los)
```

```
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
##    0.002   26.593   50.214  118.031  107.596 4153.740
```


&lt;img src="./img/los.png" width="95%" style="display: block; margin: auto;" /&gt;


---
# Challenge 5: Irregularity (frequency)

Various sampling frequency 
- High: Electrocardiogram (ECG) 
- Medium: vitals, input (e.g. medication), output (e.g. urination)
- Low: lab tests, clinical notes (done by order)
- Static: demographics, diagnosis

Example: patient in MICU for 124 hours, selected **vital** and **lab test results**

&lt;img src="./img/imgFreq.png" width="95%" style="display: block; margin: auto;" /&gt;






---
### To sum up, challenges of EHR data


- data usability 
- lack of labels
- multi-modality
- unequal length
- unequal frequency 
- ...


&lt;img src="./img/imgSam.jpg" width="70%" style="display: block; margin: auto;" /&gt;




---
# Feature / Representation learning 

Feature: a characteristic that helps with the modeling.

**Feature / Representation learning**: techniques that make it easier to extract information, eitehr to understand the data structure, or when building predictive models 

--

#### Motivations
- Feature **Engineering** vs **Learning** 

- Dimension reduction (*PCA*)
  - visualization (clustering, e.g. *K-means*)
  - memory saving (in the early days, e.g. *symbolic aggregation*)

- Predictive performance (*Lasso*, *Autoencoder, RNN*)
  
- Capture pattern from multiple modes such as time (*tensor*)



---
### Example 1: Autoencoder 

Non probablistic, direct encoding: parametric map from input to representation
&lt;img src="./img/imgAE.png" width="70%" style="display: block; margin: auto;" /&gt;

- **Encoder**: `\(h = f_\theta (x) = s_f (b + Wx)\)` 
- **Decoder**: `\(g_\theta (h) = s_g (d + W'h)\)`
  - Activation functions: linear, sigmoid, hyperbolic tangent 
  
  
- Minimise **reconstruction** error: `\(L(x, g_\theta (f_\theta(x)))\)`
  - Squared loss, binary cross-entropy loss

--

- In some cases the 'bottle-neck' hidden layer is used as representation. 
- Variations: Denoising AE, Sparse AE, Variational AE etc 

---
### Example 2: Tensor decomposition 

Tensor: multi-dimensional array 
- order 0: scalar
- order 1: vector 
- order 2: matrix
- order 3: cube 

--

### CP: CANDECOMP/PARAFAC 
Express a tensor into a sum of finite number of rank-one tensors (i.e. can be written by the outer product of `\(N\)` vectors)


&lt;img src="./img/imgCP.png" width="70%" style="display: block; margin: auto;" /&gt;

Factor matrices: combination of vectors `\(A = [\textbf{a}_1 \quad \textbf{a}_2... \textbf{a}_R ]\)`

---

### Tucker decomposition
(Higher order SVD, N-mode PCA): a tensor into a core tensor multiplied by matrix along the sides; factor matrices are usually orthogonal

&lt;img src="./img/imgTucker.png" width="50%" style="display: block; margin: auto;" /&gt;

--
### PARAFAC2

&lt;img src="./img/imgPF2.png" width="70%" style="display: block; margin: auto;" /&gt;

Applications: phenotyping with varying measurements

---

### Application in computational phenotyping 

**Phenotyping**: identify patients with certain characteristics of interest. As simple as Type 2 Diabetes

Example: &lt;span style = 'color:maroon'&gt;(Ho 2014)&lt;/span&gt;

&lt;img src="./img/imgTP.png" width="60%" style="display: block; margin: auto;" /&gt;

Phenotype interpretation: 
&lt;img src="./img/imgTP2.png" width="40%" style="display: block; margin: auto;" /&gt;



---
## Representation: Evaluation

What is a good representation? 

&lt;span style = 'color:maroon'&gt;(Bengio 2014)&lt;/span&gt; Sparsity, temporal and spatial coherent, smoothness, ... 

--
#### More practical standards:  

- Representation themselves
  - no standard metric, depend on the problems 
  - custom metrics (e.g. 'Medical concept similarity measure'&lt;span style = 'color:maroon'&gt;(Choi 2016)&lt;/span&gt;)
  - visualization (e.g. heatmap)
  
- Classification performances

  - AUC, accuracy, precision, recall, ... 




---
## Current project (using MIMIC data)

#### Objective: 
Investigate patient representation options, better representation means better accuracy in prediction of in-hospital mortality
&lt;br&gt;
.full-width[.content-box-yellow[Backstory: we were inspired by Suresh 2018 study, hence the objective and choice of inputs]]


Options for representation

1. LSTM AE (Suresh 2018 paper)

2. Our experiment: feature similarity tensor decomposition 


---
## Long short term memory Autoencoder (LSTM AE)

Suresh, Gong, Guttag 2018 Paper @ KDD: 

**Learning Tasks for Multi-task Learning: Heterogenous Patient Population in ICU**

Key idea: 
- Input: 29 variables (static and dynamic)
- first 24 hours dynamic records
- use LSTM AE to embed patient data from 3 modes: time, features, patient
- predictive task: mortality at hour 36

&lt;img src="./img/imgSuresh.png" width="100%" style="display: block; margin: auto;" /&gt;




---
Choice of inputs: 

&lt;img src="./img/imgFeatures.png" width="80%" style="display: block; margin: auto;" /&gt;



#### Implementation: 

- Keras 
- Input dimension: `n_samples * n_timesteps * n_features`
- Embedded: `n_samples * n_latent` 
    - (100, the elbow in reconstruction error curve on validation set)
- Clusters: Gaussian mixture model, 3 clusters(for best performance)
- Prediction: 

#### Performance
AUC &gt; 0.8 across different setups 

---
## Similarity tensor decomposition  
(! testing stage! )

Key ideas
- utilise whole series, not only first 24 hours

- deal with irregularity and missingness: **use feature similarity instead of individual series**

  - natural cluster: better performance in personalized predictive tasks 
  
- Tensor decomposition on feature-similarity tensor

- Representation: factor matrix 

---
## Feature similarity

Trying out 2 things: 

**SAX** (Symbolic Aggregate Approximation): raw time series into discrete symbols 

  - Dimension reduction 

--
**Dynamic Time Warping** 

  - similarity measure for time series data
  - computes the most optimal warping alignment path - unequal length!
  - applications in TS clusterng / classification


&lt;img src="./img/imgDTW.png" width="40%" style="display: block; margin: auto;" /&gt;

---
## Future plans 

Investigate different configurations

Test predictive performance

Compare with Suresh 2018 study

...
--

&lt;img src="./img/imgclosing3.png" width="100%" style="display: block; margin: auto;" /&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
